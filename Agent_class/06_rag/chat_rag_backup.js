import readline from "node:readline";
import { ChatOllama } from "@langchain/ollama";
import { ChatPromptTemplate } from "@langchain/core/prompts";
import { InMemoryChatMessageHistory } from "@langchain/core/chat_history";
import {
  RunnableSequence,
  RunnableWithMessageHistory,
} from "@langchain/core/runnables";
import { search, initDB } from "./rag_search.js";

// é¢œè‰²
const C = {
  dim: "\x1b[2m",
  yellow: "\x1b[33m",
  green: "\x1b[32m",
  cyan: "\x1b[36m",
  magenta: "\x1b[35m",
  reset: "\x1b[0m",
};

function line() {
  console.log(
    C.dim + "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€" + C.reset
  );
}

// LLM
const model = new ChatOllama({ model: "llama3.1:8b" });

const prompt = ChatPromptTemplate.fromMessages([
  ["system", "ä½ æ˜¯ä¸€ä¸ª AI åŠ©æ‰‹ï¼Œä¼šæ ¹æ®çŸ¥è¯†åº“å†…å®¹è¿›è¡Œå›ç­”ã€‚"],
  ["placeholder", "{history}"],
  [
    "human",
    `ç”¨æˆ·é—®é¢˜ï¼š{input}
æ£€ç´¢åˆ°çš„çŸ¥è¯†ï¼š
{docs}

è¯·ç»“åˆçŸ¥è¯†åº“å†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚`,
  ],
]);

const chain = RunnableSequence.from([prompt, model]);

const store = new Map();
const chat = new RunnableWithMessageHistory({
  runnable: chain,
  getMessageHistory: (sid) =>
    store.has(sid)
      ? store.get(sid)
      : store.set(sid, new InMemoryChatMessageHistory()).get(sid),
  inputMessagesKey: "input",
  historyMessagesKey: "history",
});

// readline
const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout,
});

// å…¨å±€é”™è¯¯å¤„ç†
process.on('uncaughtException', (error) => {
  console.error(C.magenta + "âŒ æœªæ•è·çš„å¼‚å¸¸:", error.message + C.reset);
  rl.close();
  process.exit(1);
});

process.on('unhandledRejection', (reason, promise) => {
  console.error(C.magenta + "âŒ æœªå¤„ç†çš„Promiseæ‹’ç»:", reason + C.reset);
  rl.close();
  process.exit(1);
});

async function main() {
  try {
    await initDB();

    console.log(C.cyan + "\nâœ¨ RAGå¢å¼ºAIåŠ©æ‰‹å¯åŠ¨ï¼" + C.reset);
    line();

    const sessionId = "rag-session";

    while (true) {
      const userInput = await new Promise((res) =>
        rl.question(C.yellow + "ğŸ§‘ ä½ ï¼š" + C.reset, res)
      );

    if (["exit", "quit"].includes(userInput.toLowerCase())) {
      console.log(C.magenta + "ğŸ‘‹ å†è§ï¼" + C.reset);
      rl.close();
      break;
    }

    // æŸ¥è¯¢çŸ¥è¯†åº“
    let results = [];
    try {
      results = await search(userInput, 3);
    } catch (err) {
      console.error(C.magenta + "âŒ çŸ¥è¯†åº“æŸ¥è¯¢å¤±è´¥:", err.message + C.reset);
    }

    const docList =
      results.length > 0
        ? results.map((r, idx) => `ã€${idx + 1}ã€‘${r.text}`).join("\n")
        : "ï¼ˆæœªæ£€ç´¢åˆ°ç›¸å…³çŸ¥è¯†ï¼‰";

    console.log(C.green + "ğŸ” æ£€ç´¢ç»“æœï¼š" + C.reset);
    console.log(docList);
    line();

    console.log(C.green + "ğŸ¤– AIï¼š" + C.reset);

    const stream = await chat.stream(
      { input: userInput, docs: docList },
      { configurable: { sessionId } }
    );

    for await (const chunk of stream) {
      if (chunk?.content) process.stdout.write(chunk.content);
    }

    console.log("\n");
    line();
  }
  } catch (error) {
    console.error(C.magenta + "âŒ ç¨‹åºé”™è¯¯:", error.message + C.reset);
    console.error(error.stack);
  } finally {
    rl.close();
    process.exit(0);
  }
}

main().catch(error => {
  console.error(C.magenta + "âŒ å¯åŠ¨å¤±è´¥:", error.message + C.reset);
  process.exit(1);
});
